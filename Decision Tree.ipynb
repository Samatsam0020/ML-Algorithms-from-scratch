{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5141fa90-c347-4385-8b69-54f7a2310829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290e1996-a217-40b8-9c57-a9fcfb42e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    # Initialisation d'un nœud dans un arbre de décision.\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        \"\"\"\n",
    "        :param feature: Index de la caractéristique (colonne) utilisée pour diviser les données (None pour les feuilles).\n",
    "        :param threshold: Seuil utilisé pour diviser les données basées sur la caractéristique (None pour les feuilles).\n",
    "        :param left: Nœud enfant gauche, représentant les données qui satisfont la condition (valeurs <= seuil).\n",
    "        :param right: Nœud enfant droit, représentant les données qui ne satisfont pas la condition (valeurs > seuil).\n",
    "        :param value: Valeur attribuée au nœud si c'est un nœud feuille (ex. une classe pour un problème de classification).\n",
    "        \"\"\"\n",
    "        self.feature = feature  # Caractéristique à tester à ce nœud (None pour un nœud feuille).\n",
    "        self.threshold = threshold  # Seuil de division basé sur la caractéristique (None pour un nœud feuille).\n",
    "        self.left = left  # Sous-arbre gauche (None si pas encore défini).\n",
    "        self.right = right  # Sous-arbre droit (None si pas encore défini).\n",
    "        self.value = value  # Valeur du nœud feuille (None si ce n'est pas une feuille).\n",
    "        \n",
    "    def is_leaf_node(self):\n",
    "        \"\"\"\n",
    "        Vérifie si ce nœud est une feuille.\n",
    "        Un nœud est considéré comme une feuille s'il contient une valeur spécifique (value n'est pas None).\n",
    "        \"\"\"\n",
    "        return self.value is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d890a638-5185-4d48-98c9-44b1d09960c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, n_features=None):\n",
    "        \"\"\"\n",
    "        :param min_samples_split: Nombre minimum d'échantillons requis pour diviser un nœud.\n",
    "        :param max_depth: Profondeur maximale de l'arbre.\n",
    "        :param n_features: Nombre de caractéristiques à considérer lors de la recherche de la meilleure division.\n",
    "        \"\"\"\n",
    "        self.min_samples_split = min_samples_split  # Critère d'arrêt basé sur le nombre d'échantillons.\n",
    "        self.max_depth = max_depth  # Limite la profondeur de l'arbre.\n",
    "        self.n_features = n_features  # Nombre de caractéristiques à utiliser pour la division.\n",
    "        self.root = None  # Racine de l'arbre, qui sera définie après l'entraînement.\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Entraîne l'arbre de décision en construisant un arbre à partir des données d'entrée X et y.\n",
    "        \"\"\"\n",
    "        # Détermine le nombre de caractéristiques à utiliser (soit toutes, soit limitées par n_features).\n",
    "        self.n_features = X.shape[1] if not self.n_features else min(X.shape[1], self.n_features)\n",
    "        # Construit l'arbre de manière récursive.\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        \"\"\"\n",
    "        Construit récursivement l'arbre de décision en divisant les données.\n",
    "        :param X: Données d'entrée.\n",
    "        :param y: Labels correspondants.\n",
    "        :param depth: Profondeur actuelle du nœud.\n",
    "        \"\"\"\n",
    "        n_samples, n_feats = X.shape  # Nombre d'échantillons et de caractéristiques.\n",
    "        n_labels = len(np.unique(y))  # Nombre de classes uniques dans les labels.\n",
    "\n",
    "        # Critères d'arrêt : profondeur maximale atteinte, un seul label, ou trop peu d'échantillons.\n",
    "        if depth >= self.max_depth or n_labels == 1 or n_samples < self.min_samples_split:\n",
    "            leaf_value = self._most_common_label(y)  # Crée un nœud feuille avec la classe majoritaire.\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        # Sélectionne aléatoirement un sous-ensemble des caractéristiques.\n",
    "        feat_idxs = np.random.choice(n_feats, self.n_features, replace=False)\n",
    "\n",
    "        # Trouve la meilleure division.\n",
    "        best_feature, best_thresh = self._best_split(X, y, feat_idxs)\n",
    "\n",
    "        # Divise les données en deux groupes : gauche et droite.\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feature], best_thresh)\n",
    "        # Construit les sous-arbres de manière récursive.\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
    "        return Node(best_feature, best_thresh, left, right)\n",
    "\n",
    "    def _best_split(self, X, y, feat_idxs):\n",
    "        \"\"\"\n",
    "        Trouve la meilleure division en maximisant le gain d'information.\n",
    "        :param X: Données d'entrée.\n",
    "        :param y: Labels correspondants.\n",
    "        :param feat_idxs: Indices des caractéristiques à considérer.\n",
    "        \"\"\"\n",
    "        best_gain = -1  # Initialisation du meilleur gain d'information.\n",
    "        split_idx, split_threshold = None, None  # Meilleure caractéristique et seuil.\n",
    "\n",
    "        # Teste chaque caractéristique sélectionnée.\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]  # Colonne correspondant à une caractéristique.\n",
    "            thresholds = np.unique(X_column)  # Valeurs uniques pour le seuil.\n",
    "\n",
    "            for thr in thresholds:\n",
    "                # Calcule le gain d'information pour chaque seuil.\n",
    "                gain = self._information_gain(y, X_column, thr)\n",
    "\n",
    "                # Met à jour si un meilleur gain est trouvé.\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_threshold = thr\n",
    "\n",
    "        return split_idx, split_threshold\n",
    "\n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        \"\"\"\n",
    "        Calcule le gain d'information pour une division donnée.\n",
    "        :param y: Labels.\n",
    "        :param X_column: Colonne des données pour une caractéristique.\n",
    "        :param threshold: Seuil pour la division.\n",
    "        \"\"\"\n",
    "        # Entropie parent (avant division).\n",
    "        parent_entropy = self._entropy(y)\n",
    "\n",
    "        # Divise les données en deux groupes : gauche et droite.\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "\n",
    "        # Si l'une des divisions est vide, le gain est nul.\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        # Calcule l'entropie pondérée des enfants.\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r\n",
    "\n",
    "        # Calcule le gain d'information.\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "\n",
    "    def _split(self, X_column, split_thresh):\n",
    "        \"\"\"\n",
    "        Divise les données en deux groupes basés sur le seuil.\n",
    "        :param X_column: Colonne des données.\n",
    "        :param split_thresh: Seuil de division.\n",
    "        \"\"\"\n",
    "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()  # Indices pour le groupe gauche.\n",
    "        right_idxs = np.argwhere(X_column > split_thresh).flatten()  # Indices pour le groupe droit.\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        \"\"\"\n",
    "        Calcule l'entropie d'un ensemble de labels.\n",
    "        :param y: Labels.\n",
    "        \"\"\"\n",
    "        hist = np.bincount(y)  # Compte les occurrences des classes.\n",
    "        ps = hist / len(y)  # Probabilités de chaque classe.\n",
    "        return -np.sum([p * np.log(p) for p in ps if p > 0])  # Entropie.\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        \"\"\"\n",
    "        Trouve la classe majoritaire dans les labels.\n",
    "        :param y: Labels.\n",
    "        \"\"\"\n",
    "        counter = Counter(y)\n",
    "        value = counter.most_common(1)[0][0]  # Classe avec le plus grand nombre d'occurrences.\n",
    "        return value\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Prédit les classes pour un ensemble de données.\n",
    "        :param X: Données d'entrée.\n",
    "        \"\"\"\n",
    "        # Parcourt chaque échantillon et traverse l'arbre pour prédire.\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        \"\"\"\n",
    "        Traverse l'arbre récursivement pour effectuer une prédiction.\n",
    "        :param x: Un échantillon.\n",
    "        :param node: Nœud actuel.\n",
    "        \"\"\"\n",
    "        # Si le nœud est une feuille, retourne la valeur.\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "\n",
    "        # Vérifie si l'échantillon va à gauche ou à droite.\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508f728-4063-4f88-a1a9-09922cd37b01",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e3fa27-c396-48ea-97d1-d9dd8a11b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59aed392-82c4-4585-ae7b-ce2998236df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = datasets.make_blobs(\n",
    "    n_samples = 200, n_features = 2, centers = 2, cluster_std = 1.05 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62e400dc-a037-458c-a284-3fd86292c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f650f1-b3c5-4c22-9d79-1e005e03e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42bf7d84-1d41-4edf-a8d5-40637cf5e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c4687b-7b44-42ff-8885-36203ebd705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee4a44f-b393-4505-9f44-3b88d67410d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
